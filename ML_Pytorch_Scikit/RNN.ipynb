{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce97e71-8d77-4d95-962e-ae7f6ba7b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_xh shape: torch.Size([2, 5])\n",
      "W_hh shape: torch.Size([2, 2])\n",
      "b_xh shape: torch.Size([2])\n",
      "b_hh shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "rnn_layer = nn.RNN(input_size=5, hidden_size=2, num_layers=1, batch_first=True) \n",
    "\n",
    "w_xh = rnn_layer.weight_ih_l0\n",
    "w_hh = rnn_layer.weight_hh_l0\n",
    "b_xh = rnn_layer.bias_ih_l0\n",
    "b_hh = rnn_layer.bias_hh_l0\n",
    "\n",
    "print('W_xh shape:', w_xh.shape)\n",
    "print('W_hh shape:', w_hh.shape)\n",
    "print('b_xh shape:', b_xh.shape)\n",
    "print('b_hh shape:', b_hh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d8e6160-8c55-4de6-b4ec-7d561eb91f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "x_seq = torch.tensor([[1.0]*5, [2.0]*5, [3.0]*5]).float()\n",
    "print(x_seq.shape)\n",
    "print(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aac96ba-7e84-42a6-9071-e72f803bfc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3520,  0.5253],\n",
      "         [-0.6842,  0.7607],\n",
      "         [-0.8649,  0.9047]]], grad_fn=<TransposeBackward1>)\n",
      "tensor([[[-0.8649,  0.9047]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## output of the simple RNN:\n",
    "output, hn = rnn_layer(torch.reshape(x_seq, (1, 3, 5)))\n",
    "print(output)\n",
    "print(hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "033e14ec-d0e3-4da3-af14-57dcb3842b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0 =>\n",
      "   Input           : [[1. 1. 1. 1. 1.]]\n",
      "   Hidden          : [[-0.4701929   0.58639044]]\n",
      "   Output (manual) : [[-0.3519801   0.52525216]]\n",
      "   RNN output      : [[-0.35198015  0.52525216]]\n",
      "\n",
      "Time step 1 =>\n",
      "   Input           : [[2. 2. 2. 2. 2.]]\n",
      "   Hidden          : [[-0.88883156  1.2364398 ]]\n",
      "   Output (manual) : [[-0.68424344  0.76074266]]\n",
      "   RNN output      : [[-0.68424344  0.76074266]]\n",
      "\n",
      "Time step 2 =>\n",
      "   Input           : [[3. 3. 3. 3. 3.]]\n",
      "   Hidden          : [[-1.3074702  1.8864892]]\n",
      "   Output (manual) : [[-0.8649416  0.9046636]]\n",
      "   RNN output      : [[-0.8649416   0.90466356]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_seq = torch.tensor([[1.0]*5, [2.0]*5, [3.0]*5]).float()\n",
    "\n",
    "## output of the simple RNN:\n",
    "output, hn = rnn_layer(torch.reshape(x_seq, (1, 3, 5)))\n",
    "\n",
    "## manually computing the output:\n",
    "out_man = []\n",
    "for t in range(3):\n",
    "    xt = torch.reshape(x_seq[t], (1, 5))\n",
    "    print(f'Time step {t} =>')\n",
    "    print('   Input           :', xt.numpy())\n",
    "    \n",
    "    ht = torch.matmul(xt, torch.transpose(w_xh, 0, 1)) + b_xh    \n",
    "    print('   Hidden          :', ht.detach().numpy())\n",
    "    \n",
    "    if t>0:\n",
    "        prev_h = out_man[t-1]\n",
    "    else:\n",
    "        prev_h = torch.zeros((ht.shape))\n",
    "\n",
    "    ot = ht + torch.matmul(prev_h, torch.transpose(w_hh, 0, 1)) + b_hh\n",
    "    ot = torch.tanh(ot)\n",
    "    out_man.append(ot)\n",
    "    print('   Output (manual) :', ot.detach().numpy())\n",
    "    print('   RNN output      :', output[:, t].detach().numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a7c9082-3e31-4b98-b267-f1f4d8bc6703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "hidden shape:  torch.Size([2, 5, 32])\n",
      "tensor([[ 0.3586, -0.4515, -0.0997,  0.5056,  0.5037, -0.2450,  0.0333, -0.4629,\n",
      "         -0.2926, -0.5758, -0.3753, -0.0839,  0.3121,  0.2695, -0.3496,  0.1267,\n",
      "          0.3111,  0.1281,  0.0380,  0.4880, -0.3908,  0.3196,  0.0031,  0.1222,\n",
      "         -0.0567, -0.2905,  0.6298, -0.2787,  0.6107, -0.4174, -0.0970,  0.7040],\n",
      "        [-0.1414,  0.0999, -0.1051, -0.0415, -0.1115, -0.3676, -0.4769,  0.6230,\n",
      "         -0.3231, -0.3659,  0.1538, -0.3719, -0.1580,  0.0735,  0.2266, -0.5426,\n",
      "          0.4008,  0.2700, -0.3152, -0.8014, -0.3004,  0.4055, -0.1981, -0.3142,\n",
      "          0.0108,  0.2815,  0.1048, -0.1704, -0.1110, -0.5390, -0.3419, -0.2502],\n",
      "        [-0.5836, -0.1876,  0.0863,  0.1653, -0.4559, -0.3938, -0.5506, -0.4074,\n",
      "          0.2435, -0.0051,  0.2634, -0.0991, -0.3347,  0.1250, -0.5264, -0.4547,\n",
      "          0.0811, -0.3026,  0.2732,  0.1153, -0.2197, -0.0578, -0.5607, -0.3266,\n",
      "         -0.3147, -0.1747, -0.1393, -0.2280, -0.1086,  0.2284,  0.3678,  0.4721],\n",
      "        [-0.1093, -0.5979,  0.1085, -0.0794,  0.0929, -0.5486,  0.5336,  0.5767,\n",
      "          0.1674, -0.3400, -0.3733, -0.5099,  0.1100,  0.3954,  0.5957, -0.5828,\n",
      "          0.1815, -0.3458,  0.1251, -0.4988, -0.7552,  0.4535, -0.0146,  0.2569,\n",
      "         -0.0766,  0.6279,  0.6667, -0.0937,  0.0298, -0.4994,  0.2267,  0.5239],\n",
      "        [ 0.2734, -0.6598,  0.0613,  0.3915,  0.3555, -0.3727, -0.0468, -0.2705,\n",
      "         -0.5809,  0.0486,  0.0214,  0.5563, -0.3195, -0.1880,  0.1599,  0.0181,\n",
      "          0.1772, -0.1270, -0.1777,  0.3709,  0.4253, -0.4318, -0.3599,  0.5470,\n",
      "          0.0581,  0.4814, -0.1229, -0.3779, -0.2222, -0.3851, -0.1300,  0.6317]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "out shape:  torch.Size([5, 32])\n",
      "tensor([[ 0.3586, -0.4515, -0.0997,  0.5056,  0.5037, -0.2450,  0.0333, -0.4629,\n",
      "         -0.2926, -0.5758, -0.3753, -0.0839,  0.3121,  0.2695, -0.3496,  0.1267,\n",
      "          0.3111,  0.1281,  0.0380,  0.4880, -0.3908,  0.3196,  0.0031,  0.1222,\n",
      "         -0.0567, -0.2905,  0.6298, -0.2787,  0.6107, -0.4174, -0.0970,  0.7040],\n",
      "        [-0.1414,  0.0999, -0.1051, -0.0415, -0.1115, -0.3676, -0.4769,  0.6230,\n",
      "         -0.3231, -0.3659,  0.1538, -0.3719, -0.1580,  0.0735,  0.2266, -0.5426,\n",
      "          0.4008,  0.2700, -0.3152, -0.8014, -0.3004,  0.4055, -0.1981, -0.3142,\n",
      "          0.0108,  0.2815,  0.1048, -0.1704, -0.1110, -0.5390, -0.3419, -0.2502],\n",
      "        [-0.5836, -0.1876,  0.0863,  0.1653, -0.4559, -0.3938, -0.5506, -0.4074,\n",
      "          0.2435, -0.0051,  0.2634, -0.0991, -0.3347,  0.1250, -0.5264, -0.4547,\n",
      "          0.0811, -0.3026,  0.2732,  0.1153, -0.2197, -0.0578, -0.5607, -0.3266,\n",
      "         -0.3147, -0.1747, -0.1393, -0.2280, -0.1086,  0.2284,  0.3678,  0.4721],\n",
      "        [-0.1093, -0.5979,  0.1085, -0.0794,  0.0929, -0.5486,  0.5336,  0.5767,\n",
      "          0.1674, -0.3400, -0.3733, -0.5099,  0.1100,  0.3954,  0.5957, -0.5828,\n",
      "          0.1815, -0.3458,  0.1251, -0.4988, -0.7552,  0.4535, -0.0146,  0.2569,\n",
      "         -0.0766,  0.6279,  0.6667, -0.0937,  0.0298, -0.4994,  0.2267,  0.5239],\n",
      "        [ 0.2734, -0.6598,  0.0613,  0.3915,  0.3555, -0.3727, -0.0468, -0.2705,\n",
      "         -0.5809,  0.0486,  0.0214,  0.5563, -0.3195, -0.1880,  0.1599,  0.0181,\n",
      "          0.1772, -0.1270, -0.1777,  0.3709,  0.4253, -0.4318, -0.3599,  0.5470,\n",
      "          0.0581,  0.4814, -0.1229, -0.3779, -0.2222, -0.3851, -0.1300,  0.6317]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0966],\n",
       "        [ 0.0599],\n",
       "        [ 0.1271],\n",
       "        [-0.2671],\n",
       "        [ 0.3404]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## An example of building a RNN model\n",
    "## with simple RNN layer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# Fully connected neural network with one hidden layer\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, \n",
    "                          hidden_size, \n",
    "                          num_layers=2, \n",
    "                          batch_first=True)\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, hidden = self.rnn(x)\n",
    "        print('hidden shape: ', hidden.shape)\n",
    "        out = hidden[-1, :, :]\n",
    "        print(hidden[1, :, :])\n",
    "        print('out shape: ', out.shape)\n",
    "        print(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = RNN(64, 32) \n",
    "\n",
    "print(model) \n",
    " \n",
    "model(torch.randn(5, 3, 64)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff7f8f-dfdf-4bcc-aa4d-2ea9cb66afa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
