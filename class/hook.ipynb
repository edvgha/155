{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b65ebd7-9a82-42ed-bbb1-747554f536f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8c8e95-d2f4-493c-a678-69a200f4bf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (s1): Sigmoid()\n",
      "  (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (s2): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,2)\n",
    "        self.s1 = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(2,2)\n",
    "        self.s2 = nn.Sigmoid()\n",
    "        self.fc1.weight = torch.nn.Parameter(torch.Tensor([[0.15,0.2],[0.250,0.30]]))\n",
    "        self.fc1.bias = torch.nn.Parameter(torch.Tensor([0.35]))\n",
    "        self.fc2.weight = torch.nn.Parameter(torch.Tensor([[0.4,0.45],[0.5,0.55]]))\n",
    "        self.fc2.bias = torch.nn.Parameter(torch.Tensor([0.6]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x= self.fc1(x)\n",
    "        x = self.s1(x)\n",
    "        x= self.fc2(x)\n",
    "        x = self.s2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19294c4-9bf7-47b7-b8f5-34e8101e802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.1500, 0.2000],\n",
      "        [0.2500, 0.3000]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3500], requires_grad=True), Parameter containing:\n",
      "tensor([[0.4000, 0.4500],\n",
      "        [0.5000, 0.5500]], requires_grad=True), Parameter containing:\n",
      "tensor([0.6000], requires_grad=True)]\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# parameters: weight and bias\n",
    "print(list(net.parameters()))\n",
    "# input data\n",
    "weight2 = list(net.parameters())[2]\n",
    "data = torch.Tensor([0.05,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea72771e-6f08-4f92-b5ab-87c0a241ae7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2984, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output of last layer\n",
    "out = net(data)\n",
    "target = torch.Tensor([0.01,0.99])  # a dummy target, for example\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(out, target); loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21929219-94de-4ca7-ae4f-87492c5d267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple hook class that returns the input and output of a layer during forward/backward pass\n",
    "class Hook():\n",
    "    def __init__(self, module, backward=False):\n",
    "        if backward==False:\n",
    "            self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        else:\n",
    "            self.hook = module.register_backward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "    def close(self):\n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd7646d-a812-4a45-87e9-3caa1df6d41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('fc1', Linear(in_features=2, out_features=2, bias=True)), ('s1', Sigmoid()), ('fc2', Linear(in_features=2, out_features=2, bias=True)), ('s2', Sigmoid())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net._modules.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fceb784-82f1-4492-bbb9-84d5868a2794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********  Forward Hooks Inputs & Outputs  *********\n",
      "(tensor([0.0500, 0.1000]),)\n",
      "tensor([0.3775, 0.3925], grad_fn=<ViewBackward0>)\n",
      "---------------------------------------------------\n",
      "(tensor([0.3775, 0.3925], grad_fn=<ViewBackward0>),)\n",
      "tensor([0.5933, 0.5969], grad_fn=<SigmoidBackward0>)\n",
      "---------------------------------------------------\n",
      "(tensor([0.5933, 0.5969], grad_fn=<SigmoidBackward0>),)\n",
      "tensor([1.1059, 1.2249], grad_fn=<ViewBackward0>)\n",
      "---------------------------------------------------\n",
      "(tensor([1.1059, 1.2249], grad_fn=<ViewBackward0>),)\n",
      "tensor([0.7514, 0.7729], grad_fn=<SigmoidBackward0>)\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "*********  Backward Hooks Inputs & Outputs  *********\n",
      "(tensor([[0.0392, 0.0435]]),)\n",
      "(tensor([0.0392, 0.0435]),)\n",
      "---------------------------------------------------\n",
      "(tensor([0.0392, 0.0435]),)\n",
      "(tensor([0.1625, 0.1806]),)\n",
      "---------------------------------------------------\n",
      "(tensor([[0.1868, 0.1755]]),)\n",
      "(tensor([0.1868, 0.1755]),)\n",
      "---------------------------------------------------\n",
      "(tensor([0.1868, 0.1755]),)\n",
      "(tensor([1., 1.]),)\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edvard/.local/share/virtualenvs/class-3g_iGOXS/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    }
   ],
   "source": [
    "# register hooks on each layer\n",
    "hookF = [Hook(layer[1]) for layer in list(net._modules.items())]\n",
    "hookB = [Hook(layer[1],backward=True) for layer in list(net._modules.items())]\n",
    "# run a data batch\n",
    "out=net(data)\n",
    "# backprop once to get the backward hook results\n",
    "out.backward(torch.tensor([1,1],dtype=torch.float),retain_graph=True)\n",
    "#! loss.backward(retain_graph=True)  # doesn't work with backward hooks, \n",
    "#! since it's not a network layer but an aggregated result from the outputs of last layer vs target \n",
    "\n",
    "print('***'*3+'  Forward Hooks Inputs & Outputs  '+'***'*3)\n",
    "for hook in hookF:\n",
    "    print(hook.input)\n",
    "    print(hook.output)\n",
    "    print('---'*17)\n",
    "print('\\n')\n",
    "print('***'*3+'  Backward Hooks Inputs & Outputs  '+'***'*3)\n",
    "for hook in hookB:             \n",
    "    print(hook.input)          \n",
    "    print(hook.output)         \n",
    "    print('---'*17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff6293-fb1b-45c1-ae0a-c6319578c790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "130a9415-aac3-46f1-a5a8-0fde77549823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18679804, 0.17552559])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the calculations with the print result above\n",
    "# the 4th layer - sigmoid\n",
    "forward_output = np.array([0.7514, 0.7729]) \n",
    "grad_in = np.array([1,1])  # sigmoid layer\n",
    "# grad of sigmoid(x) wrt x is: sigmoid(x)(1-sigmoid(x))\n",
    "grad_out = grad_in*(forward_output*(1-forward_output)); grad_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4361a887-5b42-4f15-b001-fe4035b46283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1868, 0.1755]\n",
      "0.36229999999999996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.18679804, 0.17552559])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 3th layer - linear\n",
    "print([0.1868, 0.1755])  # grad_input * (grad of Wx+b = (w1*x1+w2*x2)+b wrt W) \n",
    "print(0.1868 + 0.1755)   # grad of Wx+b wrt b o\n",
    "\n",
    "grad_in = torch.Tensor(grad_out)\n",
    "grad_in.view(1,-1) @ weight2;grad_out  # grad of layer output wrt input: wx+b => w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b55ac89-07a9-49ac-8078-2dc488b83d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.4000, 0.4500],\n",
       "        [0.5000, 0.5500]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5134bf1-4402-40ac-b9f9-943fd59a5abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1868, 0.1755]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_in.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181190f-39c7-433b-b297-548d7ec1b497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
